{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of fcc_book_recommendation_knn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irishka-learns/freecodecamp/blob/main/fcc_book_recommendation_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGd4NYQX1Rf_"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will create a book recommendation algorithm using **K-Nearest Neighbors**.\n",
        "\n",
        "You will use the [Book-Crossings dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/). This dataset contains 1.1 million ratings (scale of 1-10) of 270,000 books by 90,000 users. \n",
        "\n",
        "After importing and cleaning the data, use `NearestNeighbors` from `sklearn.neighbors` to develop a model that shows books that are similar to a given book. The Nearest Neighbors algorithm measures distance to determine the “closeness” of instances.\n",
        "\n",
        "Create a function named `get_recommends` that takes a book title (from the dataset) as an argument and returns a list of 5 similar books with their distances from the book argument.\n",
        "\n",
        "This code:\n",
        "\n",
        "`get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\")`\n",
        "\n",
        "should return:\n",
        "\n",
        "```\n",
        "[\n",
        "  'The Queen of the Damned (Vampire Chronicles (Paperback))',\n",
        "  [\n",
        "    ['Catch 22', 0.793983519077301], \n",
        "    ['The Witching Hour (Lives of the Mayfair Witches)', 0.7448656558990479], \n",
        "    ['Interview with the Vampire', 0.7345068454742432],\n",
        "    ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', 0.5376338362693787],\n",
        "    ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.5178412199020386]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "Notice that the data returned from `get_recommends()` is a list. The first element in the list is the book title passed in to the function. The second element in the list is a list of five more lists. Each of the five lists contains a recommended book and the distance from the recommended book to the book passed in to the function.\n",
        "\n",
        "If you graph the dataset (optional), you will notice that most books are not rated frequently. To ensure statistical significance, remove from the dataset users with less than 200 ratings and books with less than 100 ratings.\n",
        "\n",
        "The first three cells import libraries you may need and the data to use. The final cell is for testing. Write all your code in between those cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAQGqqO_vo4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b98503-0d34-475a-f7e6-9a309416ef98"
      },
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-10 10:49:40--  https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 104.26.2.33, 172.67.70.149, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘book-crossings.zip’\n",
            "\n",
            "book-crossings.zip      [  <=>               ]  24.88M  3.54MB/s    in 6.5s    \n",
            "\n",
            "2021-03-10 10:49:47 (3.80 MB/s) - ‘book-crossings.zip’ saved [26085508]\n",
            "\n",
            "Archive:  book-crossings.zip\n",
            "  inflating: BX-Book-Ratings.csv     \n",
            "  inflating: BX-Books.csv            \n",
            "  inflating: BX-Users.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NClILWOiEd6Q"
      },
      "source": [
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7JuoYCOWDsN"
      },
      "source": [
        "The code below aims to formally pass the challenge. However, I personally disagree with the approach which provides the expected values as it doesn't take into account certain things which are unclear from the task description. After the test code I provide the analysis and corresponding code which makes more sense to me, even though it doesn't produce expected results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTJ8H5JVEVTv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7d448d1a-1d47-48c8-ddf6-decf405056f0"
      },
      "source": [
        "userCounts = df_ratings.user.value_counts()\n",
        "usersList = userCounts[userCounts >= 200].index.values\n",
        "booksCounts = df_ratings.isbn.value_counts()\n",
        "booksList = booksCounts[booksCounts >= 100].index.values\n",
        "df_ratings_set = df_ratings[(df_ratings.user.isin(usersList)) & (df_ratings.isbn.isin(booksList))]\n",
        "df_ratings_set = df_ratings_set.merge(df_books, on = 'isbn')\n",
        "df_ratings_set.drop_duplicates(subset=['user', 'title'], inplace=True)\n",
        "df_ratings_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>isbn</th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>277427</td>\n",
              "      <td>002542730X</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
              "      <td>James Finn Garner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3363</td>\n",
              "      <td>002542730X</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
              "      <td>James Finn Garner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11676</td>\n",
              "      <td>002542730X</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
              "      <td>James Finn Garner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12538</td>\n",
              "      <td>002542730X</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
              "      <td>James Finn Garner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13552</td>\n",
              "      <td>002542730X</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
              "      <td>James Finn Garner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user  ...             author\n",
              "0  277427  ...  James Finn Garner\n",
              "1    3363  ...  James Finn Garner\n",
              "2   11676  ...  James Finn Garner\n",
              "3   12538  ...  James Finn Garner\n",
              "4   13552  ...  James Finn Garner\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ZUd-L1SQz7"
      },
      "source": [
        "# function to return recommended books - this will be tested\n",
        "def get_recommends(book = \"\"):\n",
        "  recommended_books = [book]\n",
        "  #creating sparce matrix\n",
        "  piv = df_ratings_set.pivot(index= 'title', columns= 'user', values='rating')\n",
        "  piv = piv.fillna(0)\n",
        "  rating_matrix = piv.values\n",
        "  #creating the model\n",
        "  neighbors = NearestNeighbors(metric = 'cosine', algorithm='brute')\n",
        "  neighbors.fit(rating_matrix)\n",
        "  #converting function input to the input for the model\n",
        "  req = np.array(piv.loc[book]).reshape(1,-1)\n",
        "  #predicting recommendations and distance\n",
        "  dist, ids = neighbors.kneighbors(req, 6)\n",
        "  books = list(piv.iloc[ids[0]].index.values)[-5:]\n",
        "  dist = list(dist[0])[-5:]\n",
        "  recommended_zip = zip(books, dist)\n",
        "  recommended = [[x[0], x[1]] for x in recommended_zip]\n",
        "  recommended_books.append(recommended[::-1])\n",
        "  return recommended_books"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eat9A2TKawHU"
      },
      "source": [
        "Use the cell below to test your function. The `test_book_recommendation()` function will inform you if you passed the challenge or need to keep trying."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd2SLCh8oxMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d77e05-8af1-481c-c5ef-e8bc79c7dead"
      },
      "source": [
        "books = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "print(books)\n",
        "\n",
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
        "  for i in range(2): \n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! 🎉🎉🎉🎉🎉\")\n",
        "  else:\n",
        "    print(\"You havn't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Where the Heart Is (Oprah's Book Club (Paperback))\", [[\"I'll Be Seeing You\", 0.8016211], ['The Weight of Water', 0.77085835], ['The Surgeon', 0.7699411], ['I Know This Much Is True', 0.7677075], ['The Lovely Bones: A Novel', 0.7234864]]]\n",
            "You passed the challenge! 🎉🎉🎉🎉🎉\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js2qXSt_XJl0"
      },
      "source": [
        "Why do i disagree with the approach above?\n",
        "1. The search of the duplicates doesn't take into account that there're number of books with the same title, but written by a different author.\n",
        "2. There're the same books with different isbns, which means that to exclude books which were rated fewer than 100 times title+author combination has to be used\n",
        "3. Consequently, combination user+title+author has to be used to remove duplicates.\n",
        "4. It is unclear how to decide which rating has to be taken into consideration when removing duplicates: first found, first non-zero, mean, mean non-zero, max, etc?\n",
        "5. It is unclear what rating 0.0 means, as in the task description it is stated that the rating ranges from 1 to 10. If zero-values mean that a book wasn't actually rated, it should be taken into consideration, when selecting books for the resulting data-set. If the fact that the book was read by a certain user to find similarities, therefore such books shouldn't be considered as unrated, therefore shouldn't be candidates to be dropped, then some adjustments have to be done to differentiate such members from zeroes of the final sparce-matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N1_7xhr9c8j"
      },
      "source": [
        "#df_books.info() #27139 records\n",
        "#double-checking that all isbns are unique\n",
        "df_books.isbn.unique().shape\n",
        "#check if there're duplicates with title\n",
        "df_books.duplicated(subset = ['title']).sum() #29225\n",
        "#compare with duplicates with title+author\n",
        "df_books.duplicated(subset=['title', 'author']).sum() #20175 => combination title+author has to be considered for duplicates search, there's m-to-1 relationship between isbn and title+author\n",
        "\n",
        "#checking if there're users who rated the same book more than once\n",
        "#df_ratings_set.duplicated(subset = ['user', 'title', 'author']).sum() #3435 => remove duplicates, turn realationship between isbn and title+author to 1-to-1 for simplicity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6olHTjBYW7SX"
      },
      "source": [
        "#merge tables\n",
        "df_ratings_adv = df_ratings.merge(df_books, on = 'isbn')\n",
        "#get the list of rated books without duplicates\n",
        "df_ratings_adv['full_name'] = df_ratings_adv['title'] + '//' + df_ratings_adv['author']\n",
        "df_ratings_adv.drop(columns=['isbn', 'author', 'title'], inplace=True)\n",
        "#calculation of the final rating: the mean, assuming that users could reasses rating, trying to get the 'average impression\n",
        "df_ratings_adv = pd.DataFrame(df_ratings_adv.groupby(['user', 'full_name']).mean('rating')).reset_index() # table with no duplicates\n",
        "  #dropping users who provided less than 200 ratings\n",
        "userCounts = df_ratings_adv.user.value_counts()\n",
        "usersList = userCounts[userCounts >= 200].index.values\n",
        "  #dropping books which were rated fewer than 100 times\n",
        "booksCounts = df_ratings_adv.full_name.value_counts()\n",
        "booksList = booksCounts[booksCounts >= 100].index.values\n",
        "df_ratings_adv = df_ratings_adv[(df_ratings_adv.user.isin(usersList)) & (df_ratings_adv.full_name.isin(booksList))]\n",
        "#dealing with 0.0 values of rating, assuming that the fact that a book was read should be taken into consideration, therefore adding 1 to all the rating values\n",
        "df_ratings_adv['rating'] = df_ratings_adv.rating.apply(lambda x: x+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynl07dn1ZTkC"
      },
      "source": [
        "#function\n",
        "def get_recommends_advanced(book = \"\"):\n",
        "  recommended_books = [book]\n",
        "  #creating sparce matrix\n",
        "  piv = df_ratings_adv.pivot(index= 'full_name', columns= 'user', values='rating')\n",
        "  piv = piv.fillna(0)\n",
        "  rating_matrix = piv.values\n",
        "  #creating the model\n",
        "  neighbors = NearestNeighbors(metric = 'cosine', algorithm='brute')\n",
        "  neighbors.fit(rating_matrix)\n",
        "  #converting function input to the input for the model\n",
        "  req = np.array(piv.loc[piv.index.str.startswith(book)]).reshape(1,-1)\n",
        "  #predicting recommendations and distance\n",
        "  dist, ids = neighbors.kneighbors(req, 6)\n",
        "  f_names = list(piv.iloc[ids[0]].index.values)[-5:]\n",
        "  books = [x.split('//')[0] for x in f_names]\n",
        "  dist = list(dist[0])[-5:]\n",
        "  recommended_zip = zip(books, dist)\n",
        "  recommended = [[x[0], x[1]] for x in recommended_zip]\n",
        "  recommended_books.append(recommended[::-1])\n",
        "  return recommended_books"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcfA3NbdebOj",
        "outputId": "89c1b92c-85b6-4829-f900-a10cdd311349"
      },
      "source": [
        "get_recommends_advanced('The Queen of the Damned (Vampire Chronicles (Paperback))')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Queen of the Damned (Vampire Chronicles (Paperback))',\n",
              " [['The Witching Hour (Lives of the Mayfair Witches)', 0.7079966933191927],\n",
              "  ['Cry to Heaven', 0.7060470249304717],\n",
              "  ['Interview with the Vampire', 0.6849759223267521],\n",
              "  ['The Tale of the Body Thief (Vampire Chronicles (Paperback))',\n",
              "   0.5039896286131911],\n",
              "  ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.48604703760195067]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}